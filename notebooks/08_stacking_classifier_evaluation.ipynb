{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 8: Stacking Classifier Evaluation\n",
    "\n",
    "This notebook evaluates a `StackingClassifier` ensemble on the 12 best-performing datasets. It combines the best individual classifiers found in previous notebooks with a final estimator to improve overall performance.\n",
    "\n",
    "The process is as follows:\n",
    "1.  **Load Best Datasets**: The list of 12 dataset filenames is loaded from `../results/top_12_datasets.joblib`.\n",
    "2.  **Load Best Base Estimators**: For each dataset, the best individual models (k-NN, Decision Tree, Random Forest, MLP, Naive Bayes) are loaded.\n",
    "3.  **Run StackingClassifier Evaluation**: A `StackingClassifier` is constructed using these base models and a `final_estimator` (Logistic Regression), trained, and evaluated.\n",
    "4.  **Save Results**: The performance results are saved to `../results/stacking_classifier_best_scores.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Configuration ---\n",
    "RESULTS_DIR = '../results/'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "BEST_DATASETS_PATH = os.path.join(RESULTS_DIR, 'top_12_datasets.joblib')\n",
    "\n",
    "try:\n",
    "    BEST_DATASETS = joblib.load(BEST_DATASETS_PATH)\n",
    "    print(f'Successfully loaded {len(BEST_DATASETS)} best datasets.')\n",
    "except FileNotFoundError:\n",
    "    print(f'Error: The file {BEST_DATASETS_PATH} was not found.')\n",
    "    print('Please run Notebook 02 first to generate the best datasets list.')\n",
    "    BEST_DATASETS = []\n",
    "\n",
    "# Paths to best scores of individual classifiers\n",
    "KNN_BEST_SCORES = os.path.join(RESULTS_DIR, 'knn_full_results.csv') \n",
    "DT_BEST_SCORES = os.path.join(RESULTS_DIR, 'decision_tree_full_results.csv')\n",
    "RF_BEST_SCORES = os.path.join(RESULTS_DIR, 'random_forest_full_results.csv')\n",
    "MLP_BEST_SCORES = os.path.join(RESULTS_DIR, 'mlp_full_results.csv')\n",
    "NB_BEST_SCORES = os.path.join(RESULTS_DIR, 'naive_bayes_full_results.csv')\n",
    "\n",
    "def get_best_model_for_dataset(dataset_name, classifier_type, score_df):\n",
    "    # Filter scores for the specific dataset and classifier type\n",
    "    df_filtered = score_df[(score_df['dataset'] == dataset_name) & (score_df['classifier'] == classifier_type)]\n",
    "    \n",
    "    if df_filtered.empty:\n",
    "        print(f"Warning: No best model found for {classifier_type} on {dataset_name}. Returning default.")\n",
    "        if classifier_type == 'kNN': return KNeighborsClassifier(n_neighbors=5)\n",
    "        if classifier_type == 'DecisionTree': return DecisionTreeClassifier(random_state=42)\n",
    "        if classifier_type == 'RandomForest': return RandomForestClassifier(random_state=42)\n",
    "        if classifier_type == 'MLP': return MLPClassifier(random_state=42)\n",
    "        if classifier_type == 'NaiveBayes': return GaussianNB() # Default for Naive Bayes\n",
    "        return None\n",
    "\n",
    "    # Get the row with the highest f1_cv_mean for this classifier on this dataset\n",
    "    best_row = df_filtered.loc[df_filtered['f1_cv_mean'].idxmax()]\n",
    "    best_params_str = best_row['best_params'] if 'best_params' in best_row and pd.notna(best_row['best_params']) else \"{}\"\n",
    "\n",
    "    # Safely convert string representation of dict to dict\n",
    "    import ast\n",
    "    try:\n",
    "        best_params = ast.literal_eval(best_params_str)\n",
    "        if not isinstance(best_params, dict): \n",
    "            best_params = {}\n",
    "    except (ValueError, SyntaxError):\n",
    "        best_params = {} \n",
    "\n",
    "    # Instantiate classifier with best parameters\n",
    "    if classifier_type == 'kNN':\n",
    "        return KNeighborsClassifier(**best_params)\n",
    "    elif classifier_type == 'DecisionTree':\n",
    "        return DecisionTreeClassifier(random_state=42, **best_params)\n",
    "    elif classifier_type == 'RandomForest':\n",
    "        return RandomForestClassifier(random_state=42, **best_params)\n",
    "    elif classifier_type == 'MLP':\n",
    "        return MLPClassifier(random_state=42, **best_params)\n",
    "    elif classifier_type == 'NaiveBayes':\n",
    "        variant = best_row.get('variant', 'GaussianNB')\n",
    "        if variant == 'MultinomialNB':\n",
    "            return MultinomialNB()\n",
    "        elif variant == 'ComplementNB':\n",
    "            return ComplementNB()\n",
    "        else:\n",
    "            return GaussianNB()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacking_results = []\n",
    "\n",
    "if BEST_DATASETS:\n",
    "    # Load all full results to get the best model for each dataset\n",
    "    knn_scores_df = pd.read_csv(KNN_BEST_SCORES)\n",
    "    dt_scores_df = pd.read_csv(DT_BEST_SCORES)\n",
    "    rf_scores_df = pd.read_csv(RF_BEST_SCORES)\n",
    "    mlp_scores_df = pd.read_csv(MLP_BEST_SCORES)\n",
    "    nb_scores_df = pd.read_csv(NB_BEST_SCORES)\n",
    "\n",
    "    for dataset_name in BEST_DATASETS:\n",
    "        start_time = time.time()\n",
    "        print(f'Evaluating StackingClassifier on {dataset_name}...')\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(RESULTS_DIR, dataset_name))\n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df.iloc[:, -1].values\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Get the best individual estimators for this dataset\n",
    "        estimators = [\n",
    "            ('knn', get_best_model_for_dataset(dataset_name, 'kNN', knn_scores_df)),\n",
    "            ('dt', get_best_model_for_dataset(dataset_name, 'DecisionTree', dt_scores_df)),\n",
    "            ('rf', get_best_model_for_dataset(dataset_name, 'RandomForest', rf_scores_df)),\n",
    "            ('mlp', get_best_model_for_dataset(dataset_name, 'MLP', mlp_scores_df)),\n",
    "            ('nb', get_best_model_for_dataset(dataset_name, 'NaiveBayes', nb_scores_df))\n",
    "        ]\n",
    "        # Filter out None if any model loading failed\n",
    "        estimators = [(name, est) for name, est in estimators if est is not None]\n",
    "\n",
    "        try:\n",
    "            stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5, n_jobs=-1, passthrough=False)\n",
    "            stacking_clf.fit(X_train_scaled, y_train)\n",
    "            y_pred = stacking_clf.predict(X_test_scaled)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            duration = time.time() - start_time\n",
    "\n",
    "            stacking_results.append({\n",
    "                'dataset': dataset_name,\n",
    "                'classifier': 'StackingClassifier',\n",
    "                'f1_cv_mean': f1,\n",
    "                'best_params': \"final_estimator=LogisticRegression\", # No grid search for stacking params yet\n",
    "                'duration_seconds': duration\n",
    "            })\n",
    "\n",
    "            print(f\"  StackingClassifier F1-score: {f1:.4f} (took {duration:.2f}s)\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating StackingClassifier on {dataset_name}: {e}\")\n",
    "\n",
    "    # --- Save the results ---\n",
    "    stacking_results_df = pd.DataFrame(stacking_results)\n",
    "    stacking_results_df.to_csv(os.path.join(RESULTS_DIR, 'stacking_classifier_best_scores.csv'), index=False)\n",
    "\n",
    "    print('\nSaved StackingClassifier evaluation results to `stacking_classifier_best_scores.csv`')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BEST_DATASETS:\n",
    "    display(stacking_results_df.sort_values(by='f1_cv_mean', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
