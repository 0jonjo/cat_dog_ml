{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 7: Voting Classifier Evaluation\n",
    "\n",
    "This notebook evaluates a `VotingClassifier` ensemble on the 12 best-performing datasets. It combines the best individual classifiers found in previous notebooks into a single, more robust model.\n",
    "\n",
    "The process is as follows:\n",
    "1.  **Load Best Datasets**: The list of 12 dataset filenames is loaded from `../results/top_12_datasets.joblib`.\n",
    "2.  **Load Best Base Estimators**: For each dataset, the best individual models (k-NN, Decision Tree, Random Forest, MLP, Naive Bayes) are loaded.\n",
    "3.  **Run VotingClassifier Evaluation**: A `VotingClassifier` is constructed using these base models, trained, and evaluated.\n",
    "4.  **Save Results**: The performance results are saved to `../results/voting_classifier_best_scores.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Configuration ---\n",
    "RESULTS_DIR = '../results/'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "BEST_DATASETS_PATH = os.path.join(RESULTS_DIR, 'top_12_datasets.joblib')\n",
    "\n",
    "try:\n",
    "    BEST_DATASETS = joblib.load(BEST_DATASETS_PATH)\n",
    "    print(f'Successfully loaded {len(BEST_DATASETS)} best datasets.')\n",
    "except FileNotFoundError:\n",
    "    print(f'Error: The file {BEST_DATASETS_PATH} was not found.')\n",
    "    print('Please run Notebook 02 first to generate the best datasets list.')\n",
    "    BEST_DATASETS = []\n",
    "\n",
    "# Paths to best scores of individual classifiers\n",
    "KNN_BEST_SCORES = os.path.join(RESULTS_DIR, 'knn_full_results.csv') # Using full results to get best k for each dataset\n",
    "DT_BEST_SCORES = os.path.join(RESULTS_DIR, 'decision_tree_full_results.csv')\n",
    "RF_BEST_SCORES = os.path.join(RESULTS_DIR, 'random_forest_full_results.csv')\n",
    "MLP_BEST_SCORES = os.path.join(RESULTS_DIR, 'mlp_full_results.csv')\n",
    "NB_BEST_SCORES = os.path.join(RESULTS_DIR, 'naive_bayes_full_results.csv')\n",
    "\n",
    "\n",
    "def get_best_model_for_dataset(dataset_name, classifier_type, score_df):\n",
    "    # Filter scores for the specific dataset and classifier type\n",
    "    df_filtered = score_df[(score_df['dataset'] == dataset_name) & (score_df['classifier'] == classifier_type)]\n",
    "    \n",
    "    if df_filtered.empty:\n",
    "        # Fallback if no specific best is found. This should not happen if previous notebooks ran correctly\n",
    "        print(f"Warning: No best model found for {classifier_type} on {dataset_name}. Returning default.")\n",
    "        if classifier_type == 'kNN': return KNeighborsClassifier(n_neighbors=5)\n",
    "        if classifier_type == 'DecisionTree': return DecisionTreeClassifier(random_state=42)\n",
    "        if classifier_type == 'RandomForest': return RandomForestClassifier(random_state=42)\n",
    "        if classifier_type == 'MLP': return MLPClassifier(random_state=42)\n",
    "        if classifier_type == 'NaiveBayes': return GaussianNB() # Default for Naive Bayes\n",
    "        return None\n",
    "\n",
    "    # Get the row with the highest f1_cv_mean for this classifier on this dataset\n",
    "    best_row = df_filtered.loc[df_filtered['f1_cv_mean'].idxmax()]\n",
    "    best_params_str = best_row['best_params'] if 'best_params' in best_row and pd.notna(best_row['best_params']) else \"{}\"\n",
    "\n",
    "    # Safely convert string representation of dict to dict\n",
    "    import ast\n",
    "    try:\n",
    "        best_params = ast.literal_eval(best_params_str)\n",
    "        if not isinstance(best_params, dict): # Ensure it's a dictionary\n",
    "            best_params = {}\n",
    "    except (ValueError, SyntaxError):\n",
    "        best_params = {} # Fallback to empty dict if parsing fails\n",
    "\n",
    "    # Instantiate classifier with best parameters\n",
    "    if classifier_type == 'kNN':\n",
    "        return KNeighborsClassifier(**best_params)\n",
    "    elif classifier_type == 'DecisionTree':\n",
    "        return DecisionTreeClassifier(random_state=42, **best_params)\n",
    "    elif classifier_type == 'RandomForest':\n",
    "        return RandomForestClassifier(random_state=42, **best_params)\n",
    "    elif classifier_type == 'MLP':\n",
    "        return MLPClassifier(random_state=42, **best_params)\n",
    "    elif classifier_type == 'NaiveBayes':\n",
    "        # For Naive Bayes, 'variant' might be stored, so we need to instantiate the correct one\n",
    "        variant = best_row.get('variant', 'GaussianNB')\n",
    "        if variant == 'MultinomialNB':\n",
    "            return MultinomialNB()\n",
    "        elif variant == 'ComplementNB':\n",
    "            return ComplementNB()\n",
    "        else:\n",
    "            return GaussianNB()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_results = []\n",
    "\n",
    "if BEST_DATASETS:\n",
    "    # Load all full results to get the best model for each dataset\n",
    "    knn_scores_df = pd.read_csv(KNN_BEST_SCORES)\n",
    "    dt_scores_df = pd.read_csv(DT_BEST_SCORES)\n",
    "    rf_scores_df = pd.read_csv(RF_BEST_SCORES)\n",
    "    mlp_scores_df = pd.read_csv(MLP_BEST_SCORES)\n",
    "    nb_scores_df = pd.read_csv(NB_BEST_SCORES)\n",
    "\n",
    "    for dataset_name in BEST_DATASETS:\n",
    "        start_time = time.time()\n",
    "        print(f'Evaluating VotingClassifier on {dataset_name}...')\n",
    "        \n",
    "        df = pd.read_csv(os.path.join(RESULTS_DIR, dataset_name))\n",
    "        X = df.iloc[:, :-1].values\n",
    "        y = df.iloc[:, -1].values\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # Get the best individual estimators for this dataset\n",
    "        estimators = [\n",
    "            ('knn', get_best_model_for_dataset(dataset_name, 'kNN', knn_scores_df)),\n",
    "            ('dt', get_best_model_for_dataset(dataset_name, 'DecisionTree', dt_scores_df)),\n",
    "            ('rf', get_best_model_for_dataset(dataset_name, 'RandomForest', rf_scores_df)),\n",
    "            ('mlp', get_best_model_for_dataset(dataset_name, 'MLP', mlp_scores_df)),\n",
    "            ('nb', get_best_model_for_dataset(dataset_name, 'NaiveBayes', nb_scores_df))\n",
    "        ]\n",
    "        # Filter out None if any model loading failed\n",
    "        estimators = [(name, est) for name, est in estimators if est is not None]\n",
    "\n",
    "        # For VotingClassifier, we need models that implement predict_proba for 'soft' voting\n",
    "        # Naive Bayes (Multinomial/Complement) might not have it. Let's ensure consistency.\n",
    "        # For simplicity and to avoid issues, we'll use 'hard' voting unless all support 'soft'.\n",
    "        try:\n",
    "            # Check if all estimators have predict_proba\n",
    "            can_soft_vote = all(hasattr(est, 'predict_proba') for _, est in estimators)\n",
    "            voting_strategy = 'soft' if can_soft_vote else 'hard'\n",
    "            if not can_soft_vote and 'nb' in [name for name, _ in estimators]:\n",
    "                print(f"Warning: Not all estimators support predict_proba for soft voting on {dataset_name}. Using hard voting.")\n",
    "\n",
    "            voting_clf = VotingClassifier(estimators=estimators, voting=voting_strategy, n_jobs=-1)\n",
    "            voting_clf.fit(X_train_scaled, y_train)\n",
    "            y_pred = voting_clf.predict(X_test_scaled)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            \n",
    "            duration = time.time() - start_time\n",
    "\n",
    "            voting_results.append({\n",
    "                'dataset': dataset_name,\n",
    "                'classifier': 'VotingClassifier',\n",
    "                'f1_cv_mean': f1,\n",
    "                'best_params': f"voting={voting_strategy}", # No grid search for voting params yet\n",
    "                'duration_seconds': duration\n",
    "            })\n",
    "\n",
    "            print(f"  VotingClassifier F1-score: {f1:.4f} (took {duration:.2f}s)")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f"Error evaluating VotingClassifier on {dataset_name}: {e}")\n",
    "\n",
    "    # --- Save the results ---\n",
    "    voting_results_df = pd.DataFrame(voting_results)\n",
    "    voting_results_df.to_csv(os.path.join(RESULTS_DIR, 'voting_classifier_best_scores.csv'), index=False)\n",
    "\n",
    "    print('\nSaved VotingClassifier evaluation results to `voting_classifier_best_scores.csv`')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Display Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if BEST_DATASETS:\n",
    "    display(voting_results_df.sort_values(by='f1_cv_mean', ascending=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
