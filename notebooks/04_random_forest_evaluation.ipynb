{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Random Forest Evaluation and Internal Statistical Analysis\n",
    "\n",
    "This notebook evaluates the Random Forest classifier on the 12 best-performing datasets. It then performs an internal statistical analysis to compare the different hyperparameter combinations for the `RandomForestClassifier`.\n",
    "\n",
    "The process is as follows:\n",
    "1.  **Load Best Datasets**: The list of 12 dataset filenames is loaded from `../results/top_12_datasets.joblib`.\n",
    "2.  **Run Random Forest Evaluation**: For each of the top datasets, `GridSearchCV` is used to find the best hyperparameters for the `RandomForestClassifier`.\n",
    "3.  **Internal Statistical Analysis**: Friedman and Nemenyi tests are performed to compare the performance of different hyperparameter combinations *within* the Random Forest classifier on the top 12 datasets.\n",
    "4.  **Save Results**: The detailed Random Forest evaluation results (including all hyperparameter combinations) are saved to `../results/random_forest_full_results.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import time\n",
    "from scipy.stats import friedmanchisquare\n",
    "import scikit_posthocs as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- Configuration ---",
    "RESULTS_DIR = '../results/'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "BEST_DATASETS_PATH = os.path.join(RESULTS_DIR, 'top_12_datasets.joblib')\n",
    "\n",
    "# Load the list of best datasets\n",
    "try:\n",
    "    BEST_DATASETS = joblib.load(BEST_DATASETS_PATH)\n",
    "    print(f'Successfully loaded {len(BEST_DATASETS)} best datasets.')\n",
    "except FileNotFoundError:\n",
    "    print(f'Error: The file {BEST_DATASETS_PATH} was not found.')\n",
    "    print('Please run Notebook 02 first to generate the best datasets list.')\n",
    "    BEST_DATASETS = []\n",
    "\n",
    "rf_grid_params = {\n",
    "    'n_estimators': [10, 20, 30, 100],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Evaluate Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [