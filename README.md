# Supervised Machine Learning for Image Classification

A step-by-step framework for a supervised machine learning project focused on image classification, using a Cat vs. Dog problem as an example.

The workflow is broken down into a series of sequential Jupyter notebooks, covering:
- Feature extraction (HOG, LBP) and dimensionality reduction (PCA).
- Model training and hyperparameter tuning for various classifiers (k-NN, Decision Tree, Random Forest, MLP, Naive Bayes).
- Ensemble methods (Voting, Stacking).
- In-depth statistical analysis at each stage.

It was developed for the `IMD3002 - SUPERVISED MACHINE LEARNING` course at the `Universidade Federal of Rio Grande do Norte`, instructed by professor Joao Carlos Xavier Junior.


The methodology includes:
1.  **Feature Extraction**: Using visual descriptors like HOG (Histogram of Oriented Gradients) and LBP (Local Binary Patterns) to convert images into a numerical format.
2.  **Model Training**: Training several types of classification models, from simple ones like k-NN and Decision Trees to more complex ones like Neural Networks and Ensembles.
3.  **Hyperparameter Tuning**: Finding the best settings for each model to maximize performance.
4.  **Statistical Evaluation**: Using statistical tests (Friedman and Nemenyi) to rigorously compare the performance of different models and their configurations.

## Repository Structure

*   `notebooks/`: Contains the refactored Jupyter notebooks to reproduce the experiments in a step-by-step manner.
    *   `01_feature_extraction.ipynb`: Extracts HOG and LBP features from all images and applies PCA, generating the initial set of datasets.
    *   `02_knn_evaluation.ipynb`: Evaluates the k-NN classifier on all generated datasets to find the top 12 best-performing ones for subsequent experiments. Also performs an internal statistical analysis on the `n_neighbors` hyperparameter.
    *   `03_decision_tree_evaluation.ipynb`: Evaluates the Decision Tree classifier on the top 12 datasets and performs an internal statistical analysis on its hyperparameters.
    *   `04_random_forest_evaluation.ipynb`: Evaluates the Random Forest classifier on the top 12 datasets and performs an internal statistical analysis on its hyperparameters.
    *   `05_mlp_evaluation.ipynb`: Evaluates the Multi-layer Perceptron (MLP) classifier on the top 12 datasets and performs an internal statistical analysis on its hyperparameters.
    *   `06_naive_bayes_evaluation.ipynb`: Evaluates the Naive Bayes classifier variants on the top 12 datasets and performs an internal statistical analysis.
    *   `07_voting_classifier_evaluation.ipynb`: Evaluates a `VotingClassifier` ensemble on the top 12 datasets.
    *   `08_stacking_classifier_evaluation.ipynb`: Evaluates a `StackingClassifier` ensemble on the top 12 datasets.
    *   `09_final_comparative_statistical_analysis.ipynb`: Performs the final statistical comparison between the best models from all previous notebooks.
*   `results/`: Contains the outputs generated by the notebooks (e.g., feature datasets, model scores).
*   `data/`: This directory should contain the dataset used in the research.
    *   `data/images/`: Place your cat and dog images here, organized into `dogs/` and `cats/` subdirectories. For example:
        ```
        data/images/
        ├── dogs/
        │   ├── dog_breed1_img1.jpg
        │   └── dog_breed2_img2.png
        └── cats/
            ├── cat_breed1_img1.jpg
            └── cat_breed2_img2.png
        ```

## Getting Started

Follow these steps to set up the environment, prepare the data, and run the experiments:

### 1. Environment Setup

It is recommended to use a virtual environment.

```bash
# Create a virtual environment
python -m venv venv

# Activate the virtual environment
# On Linux/macOS:
source venv/bin/activate
# On Windows
# .\venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```
*(Note: A `requirements.txt` file should be present or generated.)*

### 2. Prepare the Dataset

1.  **Download the Dataset**: The original paper used images from the Oxford-IIIT Pet Dataset. You will need to download a suitable subset of cat and dog images.
2.  **Organize Images**: Create `dogs/` and `cats/` subdirectories inside `data/images/` and place your respective images there.

### 3. Run the Notebooks

The notebooks in the `notebooks/` directory are designed to be run in sequential order (from 01 to 09). Each notebook builds upon the results of the previous one.

1.  **Open the `notebooks/` directory** in Jupyter (or JupyterLab).
2.  **Run the notebooks one by one**, starting from `01_feature_extraction.ipynb` and finishing with `09_final_comparative_statistical_analysis.ipynb`.

Each notebook will generate corresponding `.csv` files with its results in the `results/` directory, which are then used by subsequent notebooks.

### 4. Using Google Colab (Optional)

For users who prefer a cloud-based environment or require more computational resources, these notebooks can be easily run on Google Colab.

1.  **Upload to Colab**:
    *   Go to [Google Colab](https://colab.research.google.com/).
    *   Click on "File" -> "Upload notebook" and upload each `.ipynb` file from the `notebooks/` directory, or connect to your GitHub repository directly.
2.  **Mount Google Drive (for data and results)**:
    *   In each notebook, you might need to mount your Google Drive to access the `data/` and `results/` folders. You can do this with the following code in a cell:
        ```python
        from google.colab import drive
        drive.mount('/content/drive')
        # Then adjust your paths, e.g., RESULTS_DIR = '/content/drive/My Drive/your_repo_folder/results/'
        ```
3.  **Install Dependencies**:
    *   You will need to install the required Python packages within the Colab environment. Add a cell at the beginning of each notebook with:
        ```bash
        !pip install -r requirements.txt
        ```
    *   Make sure `requirements.txt` is also accessible (e.g., uploaded to Drive).
4.  **Run Sequentially**: Just like running locally, ensure you execute the notebooks in sequential order (01 to 09).

## Reproducibility

The configurations for feature extraction, PCA, and classifiers are set to match those described in the original paper for reproducibility.

## License

MIT License
